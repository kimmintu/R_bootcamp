---
title: "Assignment R Bootcamp"
author: "Tu Tran and Andy Gubser"
date: /today
output: 
  html_document:
    theme: flatly
    toc: true
    toc_depth: 4
    toc_float: 
      collapsed: true
      smooth_scroll: true
    number_sections: true
    df_print: paged

---

# Abstract

# Purpose / Research question

In this project we analyse on what day, during what time the typical subscriber make use of bike sharing services in New York City. Therefore, we identify subscribers by their age and gender and take into account variables such as season, weekday and daytime of the ride. We further consider weather conditions during the ride. 

# Methodology
The analysis bases on two data sets from Kaggle: the bikeshare data set for New York City in 2016 [^1 https://www.kaggle.com/samratp/bikeshare-analysis#NYC-CitiBike-2016.csv] and the corresponding weather data set [^2 https://www.kaggle.com/mathijs/weather-data-in-new-york-city-2016]. 

To approach the research question, we get a first impression by data visualisation. Then, the analysis is deepened by a linear regression model followd by a random forest model.


# Analysis

```{r setup}
## R and knitr Setup ##

# remove all objects loaded and clear memory
rm(list = ls(all.names = TRUE))
gc()

knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
knitr::opts_chunk$set(echo=TRUE)
set.seed(19)

```


## Library Import

```{r importLibraries, include=FALSE}

## load packages and install them when necessary ##

list.of.packages <- c("installr", "Hmisc", "ggmap", "tidyverse", "tidyr",
                      "viridis", "leaflet", "lubridate", "checkpoint", "zoo")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
for (p in list.of.packages){
  library(p, character.only = TRUE)
}

checkpoint(snapshotDate = "2099-12-29")


```

# Data Import

```{r dataImport, include=FALSE, echo=FALSE, }
# # preprocess bike data
# source("./d.bike_preprocessing.R")

# # preprocess weather data and merge with preprocessed bike data
# source("./d.weather_preprocessing.R")

d.bike_weather <- readRDS("./data/d.bike_weather.rds")

colnames(d.bike_weather)
summary(d.bike_weather)
dim(d.bike_weather)
length(d.bike_weather)

d.bike_weather$date

```


## Data Definition

The bike data set consists of 276'798 observation and 15 variables. These variables include the two categories user type and gender as well as the numeric birth year. User type defines if the user is a registered subscriber of the bike sharing service or a casual user, whereby we focus on subscribers. Gender says if the user is female, male or unknown. Since there are only a few user with unknown gender, we exclude them from the analysis. The continous variable age is calculated from the birth year. Further, the categorical variable age_cor is created, where users over 70 are put into a single bin in order to reduce potential bias of these observations. 
Further, the data set include start and stop time stamps as well as trip duration of individual trips, station names, ids and its coordinates. By checking for outliers, one observation was detected to have meaningless coordinates. These observations are excluded from further analysis. 
The prepared data set includes 242'746 observations and 21 variables. 

The weather data set includes 366 observations and the 7 variables maximum, minimum and average temperature, precipitation, snow fall and snow depth on specific dates. In order to merge the two data sets on the date variable, this variable is created in the bike sharing data set by extracting the date from the start timestamps. The merged data set consists of 242'746 observations and 15 variables. 


# Graphical Analysis

```{r}
head(d.bike_weather)

head(d.bike_weather %>% filter(startdate == "2016-01-04"))

```



```{r}
d.bike_weather$starthour <- hour(d.bike_weather$starttime)

d.bike_weather$weekday <- 
  factor(d.bike_weather$weekday, 
         levels = c("Montag", "Dienstag",  "Mittwoch", "Donnerstag", "Freitag", "Samstag", "Sonntag"))

d.bike_weather <- d.bike_weather %>% drop_na(age)

d.bike_weather$tripduration_min <- round(d.bike_weather$tripduration_min)
d.bike_weather$average_temperature_celsis <- round(d.bike_weather$average_temperature_celsis)
d.bike_weather$stophour <- hour(d.bike_weather$stoptime)

sub.d.bike_weather <- select(d.bike_weather, 
                             -c("tripduration", "starttime", "stoptime", "birth_year", "age_capped", 
                                "maximum_temperature", "minimum_temperature", "average_temperature", 
                                "minimum_temperature_celsius", "maximum_temperature_celsius", "usertype")) 

names(sub.d.bike_weather)[names(sub.d.bike_weather) == "tripduration_min"] <- "tripduration"

sub.d.bike_weather %>% Filter(f = is.factor) %>% names
sub.d.bike_weather$starthour <- factor(sub.d.bike_weather$starthour)
sub.d.bike_weather$stophour <- factor(sub.d.bike_weather$stophour)

str(sub.d.bike_weather)

```



```{r}

d.bike_weather %>%
  group_by(month) %>%
  summarise(median_reading = median(tripduration)) %>%
  ggplot(aes(x=month, y=median_reading, group=1)) +
  geom_line(colour = '#5EB296', size=1) +
  ggtitle('Median trip duration vs. months') +
  labs(x='Month', y='Median trip duration')

d.bike_weather %>%
  group_by(weekday) %>%
  summarise(median_reading = median(tripduration)) %>%
  ggplot(aes(x=weekday, y=median_reading, group=1)) +
  geom_line(colour = '#5EB296', size=1) +
  ggtitle('Median trip duration vs. weekdays') +
  labs(x='Weekday', y='Median trip duration')

d.bike_weather %>%
  group_by(starthour) %>%
  summarise(median_reading = median(tripduration)) %>%
  ggplot(aes(x=starthour, y=median_reading, group=1)) +
  geom_line(colour = '#5EB296', size=1) +
  ggtitle('Median trip duration vs. start hours') +
  labs(x='Start Hour', y='Median trip duration')

d.bike_weather %>%
  group_by(starthour, gender, ) %>%
  summarise(median_reading = median(tripduration)) %>%
  ggplot(aes(x=starthour, y=median_reading, group=1)) +
  geom_line(colour = '#5EB296', size=1) +
  ggtitle('Median trip duration vs. start hours') +
  labs(x='Start Hour', y='Median trip duration') +
  facet_wrap(~ gender, scales="free")

d.bike_weather %>%
  group_by(average_temperature_celsis) %>%
  summarise(median_reading = median(tripduration)) %>%
  ggplot(aes(x=average_temperature_celsis, y=median_reading, group=1)) +
  geom_line(colour = '#5EB296', size=1) +
  ggtitle('Median trip duration vs. temperature') +
  labs(x='Temperature', y='Median trip duration')

```

Linear Regression Model

```{r}

```
```{r}

holidays <- c("2016-01-01", "2016-01-18", "2016-02-12", "2016-02-15", "2016-05-30",
              "2016-07-04", "2016-09-05", "2016-10-10", "2016-11-11", "2016-11-24",
              "2016-12-26")

sub.d.bike_weather$public_holiday <- FALSE

for (day in holidays) {
  sub.d.bike_weather$public_holiday[sub.d.bike_weather$startdate == day] <- TRUE
}

```

```{r}

sub.agg <- sub.d.bike_weather %>%
  select(start_station_id, startdate, weekday, public_holiday, average_temperature_celsis, tripduration) %>%
  filter(startdate == "2016-01-01") %>%
  group_by(start_station_id, startdate, weekday, public_holiday, average_temperature_celsis) %>%
  summarize(sum_tripduration = sum(tripduration, na.rm=TRUE)) %>%
  arrange(startdate)



## TODO:
# 1. remove holidays rows
# 2. remove start - stop between 2 days rows
head(sub.d.bike_weather %>% filter(startdate == "2016-01-04"))

rentweekday <- sub.d.bike_weather %>%
  group_by(weekday) %>%
  summarise(day_avg_count = round(n() / 52))

rentweekday

rentholiday <- sub.d.bike_weather %>%
  filter(as.character(startdate) %in% holidays) %>%
  group_by(startdate) %>%
  summarise(holiday_count = n())
  arrange(startdate)
head(rentholiday)


fromstation <- d.bike_weather %>%
  filter(!weekday %in% c("Samstag", "Sonntag")) %>%
  group_by(start_station_id) %>%
  summarise(total = n(), day_avg = total / round(5*366/7)) %>%
  arrange(desc(total))
fromstation

max(d.bike_weather$tripduration_min)

dim(d.bike_weather)
dim(d.bike_weather %>% filter(weekday == "Sonntag" || weekday == "Samstag"))

dim(d.bike_weather %>% filter(weekday %in%  c("Sonntag", "Samstag")))

```
```{r}
tostation <- d.bike_weather %>%
  group_by(end_station_id) %>%
  summarise(total = n(), day_avg = total / 366) %>%
  arrange(desc(total))
tostation


```


```{r}
library(ISLR)
library(tree)

sub.d.bike_weather$tripdurationlog <- log(sub.d.bike_weather$tripduration)

# create train and test sets
set.seed(1)
train <- sample(1:nrow(sub.d.bike_weather), nrow(sub.d.bike_weather) / 2)
d.train <- sub.d.bike_weather[train, ]
d.test <- sub.d.bike_weather[-train, ]

dim(d.train)

sub.agg <- sub.d.bike_weather %>%
  select(start_station_id, startdate, weekday, public_holiday, 
         average_temperature_celsis, tripduration) %>%
  group_by(start_station_id, startdate, weekday, public_holiday, average_temperature_celsis) %>%
  summarize(sum_tripduration = sum(tripduration, na.rm=TRUE)) %>%
  arrange(startdate)

head(sub.agg)
str(sub.agg)

sub.agg$start_station_id <- as.numeric(sub.agg$start_station_id)

# fitting tree model
tree.model <- tree(sum_tripduration ~ . - sum_tripduration, data = sub.agg)
tree.model
summary(tree.model)

# ploting model
plot(tree.model)
text(tree.model)

# predicted error
yhat <- predict(tree.carseats, newdata = Carseats.test)
mean((yhat - Carseats.test$Sales)^2)

# cross validation determines optimal level of tree complexity
cv.carseats <- cv.tree(tree.carseats)
plot(cv.carseats$size, cv.carseats$dev, type = "b")
tree.min <- which.min(cv.carseats$dev)
points(tree.min, cv.carseats$dev[tree.min], col = "red", cex = 2, pch = 20)

# prune tree
prune.carseats <- prune.tree(tree.carseats, best = 8)
plot(prune.carseats)
text(prune.carseats, pretty = 0)

# predicted error of pruned tree
yhat <- predict(prune.carseats, newdata = Carseats.test)
mean((yhat - Carseats.test$Sales)^2)

# bagging tree & predicted error
bag.carseats <- randomForest(Sales ~ ., data = Carseats.train, mtry = 10, ntree = 500, importance = TRUE)
yhat.bag <- predict(bag.carseats, newdata = Carseats.test)
mean((yhat.bag - Carseats.test$Sales)^2)

# important predictors
importance(bag.carseats)

# randomforest & predicted error
rf.carseats <- randomForest(Sales ~ ., data = Carseats.train, mtry = 3, ntree = 500, importance = TRUE)
yhat.rf <- predict(rf.carseats, newdata = Carseats.test)
mean((yhat.rf - Carseats.test$Sales)^2)

# important predictors
importance(rf.carseats)


```



```{r}
str(sub.d.bike_weather)
sub.d.bike_weather$start_station_id <- as.numeric(sub.d.bike_weather$start_station_id)


```


```{r}
str(sub.d.bike_weather)

lm.fit <- lm(log(tripduration) ~ weekday + public_holiday 
             , data=sub.d.bike_weather)

plot(lm.fit)

lm.fit <- lm(log(tripduration) ~ age, data=sub.d.bike_weather)



summ <- summary(lm.fit)


modcoef <- summ[["coefficients"]]

summ
modcoef

modcoef[ , 4] <- round(modcoef[ , 4], 3)
modcoef[order(modcoef[0:20 , 4]), ]  

# save the model to disk
saveRDS(lm.fit, "./data/lm_model_log.rds")
 
# load the model
#read_model <- readRDS("./data/lm_model.rds")
#read_summ <- summary(read_model)


```


```{r}
colnames(d.bike_weather)

# tripduration
hist(d.bike_weather$tripduration)
hist(log(d.bike_weather$tripduration))

# station id
hist(as.numeric(d.bike_weather$start_station_id))
hist(as.numeric(d.bike_weather$end_station_id))

# birth_year
describe(d.bike_weather$birth_year)
hist(as.numeric(d.bike_weather$age_capped))

# weather
hist(d.bike_weather$maximum_temperature_celsius)
hist(d.bike_weather$minimum_temperature_celsius)
hist(d.bike_weather$average_temperature_celsius)

describe(d.bike_weather$precipitation)
describe(d.bike_weather$snow_fall)
describe(d.bike_weather$snow_depth)

typeof(d.bike_weather$snow_depth)




```


## Feature Selection

```{r corrplot}
# round(cor(dplyr::select_if(d.bike_weather, is.numeric)),2)

rquery.cormat<-function(x,
                        type=c('lower', 'upper', 'full', 'flatten'),
                        graph=TRUE,
                        graphType=c("correlogram", "heatmap"),
                        col=NULL, ...)
{
  library(corrplot)
  # Helper functions
  #+++++++++++++++++
  # Compute the matrix of correlation p-values
  cor.pmat <- function(x, ...) {
    mat <- as.matrix(x)
    n <- ncol(mat)
    p.mat<- matrix(NA, n, n)
    diag(p.mat) <- 0
    for (i in 1:(n - 1)) {
      for (j in (i + 1):n) {
        tmp <- cor.test(mat[, i], mat[, j], ...)
        p.mat[i, j] <- p.mat[j, i] <- tmp$p.value
      }
    }
    colnames(p.mat) <- rownames(p.mat) <- colnames(mat)
    p.mat
  }
  # Get lower triangle of the matrix
  getLower.tri<-function(mat){
    upper<-mat
    upper[upper.tri(mat)]<-""
    mat<-as.data.frame(upper)
    mat
  }
  # Get upper triangle of the matrix
  getUpper.tri<-function(mat){
    lt<-mat
    lt[lower.tri(mat)]<-""
    mat<-as.data.frame(lt)
    mat
  }
  # Get flatten matrix
  flattenCorrMatrix <- function(cormat, pmat) {
    ut <- upper.tri(cormat)
    data.frame(
      row = rownames(cormat)[row(cormat)[ut]],
      column = rownames(cormat)[col(cormat)[ut]],
      cor  =(cormat)[ut],
      p = pmat[ut]
    )
  }
  # Define color
  if (is.null(col)) {
    col <- colorRampPalette(
            c("#67001F", "#B2182B", "#D6604D", "#F4A582",
              "#FDDBC7", "#FFFFFF", "#D1E5F0", "#92C5DE", 
             "#4393C3", "#2166AC", "#053061"))(200)
    col<-rev(col)
  }
  
  # Correlation matrix
  cormat<-signif(cor(x, use = "complete.obs", ...),2)
  pmat<-signif(cor.pmat(x, ...),2)
  # Reorder correlation matrix
  ord<-corrMatOrder(cormat, order="hclust")
  cormat<-cormat[ord, ord]
  pmat<-pmat[ord, ord]
  # Replace correlation coeff by symbols
  sym<-symnum(cormat, abbr.colnames=FALSE)
  # Correlogram
  if(graph & graphType[1]=="correlogram"){
    corrplot(cormat, type=ifelse(type[1]=="flatten", "lower", type[1]),
             tl.col="black", tl.srt=45,col=col,...)
  }
  else if(graphType[1]=="heatmap")
    heatmap(cormat, col=col, symm=TRUE)
  # Get lower/upper triangle
  if(type[1]=="lower"){
    cormat<-getLower.tri(cormat)
    pmat<-getLower.tri(pmat)
  }
  else if(type[1]=="upper"){
    cormat<-getUpper.tri(cormat)
    pmat<-getUpper.tri(pmat)
    sym=t(sym)
  }
  else if(type[1]=="flatten"){
    cormat<-flattenCorrMatrix(cormat, pmat)
    pmat=NULL
    sym=NULL
  }
  list(r=cormat, p=pmat, sym=sym)
}

rquery.cormat(dplyr::select_if(d.bike_weather, is.numeric))

```


```{r}
# average_temperature_celsius
# presipiation

colnames(d.bike_weather)

ggplot(data = d.bike_weather, 
       aes(
         y = log(tripduration), 
         x = age, 
         color=gender))+ 
  geom_point(alpha=0.1) +
  geom_smooth(method='lm', formula= y~x)

```


# Linear Model

```{r, include=FALSE, echo=FALSE}
# get background map
min_lon <- min(d.bike_weather$start_station_longitude, d.bike_weather$end_station_longitude)
max_lon <- max(d.bike_weather$start_station_longitude, d.bike_weather$end_station_longitude)
min_lat <- min(d.bike_weather$start_station_latitude, d.bike_weather$end_station_latitude)
max_lat <- max(d.bike_weather$start_station_latitude, d.bike_weather$end_station_latitude)

mad_map <- (map <- get_map(c(left = min_lon, bottom = min_lat, 
                             right = max_lon, top = max_lat)))

# take a random sample of size 1%
d.bike_weather_sample = d.bike_weather[
  base::sample(x=1:nrow(d.bike_weather), round(nrow(d.bike_weather)*1/100)), ]


```



```{r}
#final map

#ggmap(mad_map) + 
#  geom_leg(
#    data=d.bike_weather_sample,
#      # color = factor(gender), 
#      alpha=0.1,
#      aes(
#        color = age_corr,
#        x = start_station_longitude, 
#        y = start_station_latitude, 
#        xend = end_station_longitude, 
#        yend = end_station_latitude
#        )
#      )+
#  labs(x="",y="") +
#  facet_grid(month ~ gender) +
#  theme(
#    axis.title.x=element_blank(),
#    axis.text.x=element_blank(),
#    axis.ticks.x=element_blank(),
#    axis.title.y=element_blank(),
#    axis.text.y=element_blank(),
#    axis.ticks.y=element_blank()
#    ) + 
#  scale_color_viridis(option = "magma")

#ggsave("map_age_gender_month.pdf", device = "pdf")
```


```{r}
# Set value for the minZoom and maxZoom settings.
#leaflet(options = leafletOptions(minZoom = 0, maxZoom = 18))

#m <- leaflet() %>%
#  addTiles() %>%  # Add default OpenStreetMap map tiles
#  addMarkers(lng=d.bike_weather$start_station_longitude, 
#             lat=d.bike_weather$start_station_latitude, 
#             popup="The birthplace of R")
#m  # Print the map

```


```{r}

colnames(d.bike_weather)


```


# Fit models





# Check Results (output and graphs)





# Interpretation





```{r}
# sessionInfo()
# {miniCRAN} pkgDep()

```
